{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "lastEditStatus": {
   "notebookId": "buzz533qbguepjgb7hcl",
   "authorId": "5095547476787",
   "authorName": "EBOTWICK",
   "authorEmail": "elliott.botwick@snowflake.com",
   "sessionId": "b79daa92-a8d2-446a-a0fb-e18deacb9deb",
   "lastEditTime": 1756836063680
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "id": "a1ee390b-c216-4c30-9cef-15e61b5a1acd",
   "metadata": {
    "language": "python",
    "name": "python_import"
   },
   "outputs": [],
   "source": "import pandas as pd\nimport numpy as np\n\nimport snowflake.core\nfrom snowflake.snowpark import Session\nfrom snowflake.core import Root\nimport snowflake.snowpark as snowpark\nfrom snowflake.snowpark.context import get_active_session\nfrom snowflake.cortex import complete\n\nfrom typing import List\nimport os\nimport sys\nimport json\nimport time\nimport requests\n\n#Set up snowflake session vars and env vars\nsession = get_active_session()\nroot = Root(session)\n\n#Enable OpenTelemetry Tracing\nos.environ[\"TRULENS_OTEL_TRACING\"] = \"1\"",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "86161c8a-fa0a-46b2-8368-a279c00be836",
   "metadata": {
    "language": "python",
    "name": "define_vars",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "DB_NAME = \"CHUNKING_EVAL_DEMO\"\nSCHEMA_NAME = \"DATA\"\nSTAGE_NAME = \"DOCS\"\nWH_NAME = \"CHUNKING_EVAL_WAREHOUSE\"",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65daf34a-f360-4223-bff2-60f016ff6c3e",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "query_css_raw_chunks",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "#Access cortex search retriever built in 1st notebook\ntest_query = \"How did the economic outlook change over the course of 2023?\"\n\n\ncortex_search_service = (\n    root\n    .databases[DB_NAME]\n    .schemas[SCHEMA_NAME]\n    .cortex_search_services[\"FOMC_RAW_TEXT_RETRIEVAL\"]\n)\nresp = cortex_search_service.search(\n    query=test_query,\n    columns=[\"SEARCH_COL\"],\n    limit=3,\n)\n\nsearch_results = [(row[\"SEARCH_COL\"]) for row in resp.results] if resp.results else []\n\nsearch_results"
  },
  {
   "cell_type": "code",
   "id": "7b6a0b34-68e5-4c65-899c-fc104cf2bb88",
   "metadata": {
    "language": "python",
    "name": "query_css_chunks_with_summaries"
   },
   "outputs": [],
   "source": "#Access cortex search retriever built in 1st notebook\ntest_query = \"How did the economic outlook change over the course of 2023?\"\n\n\ncortex_search_service = (\n    root\n    .databases[DB_NAME]\n    .schemas[SCHEMA_NAME]\n    .cortex_search_services[\"FOMC_TAGGED_CHUNK_RETRIEVAL\"]\n)\nresp = cortex_search_service.search(\n    query=test_query,\n    columns=[\"SEARCH_COL\"],\n    limit=3,\n)\n\nsearch_results = [(row[\"SEARCH_COL\"]) for row in resp.results] if resp.results else []\n\nsearch_results",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b51fe4-118c-437c-a348-462d2fb25f58",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "DefineRAGClass",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# Create the RAGWithObservability class to structure the RAG pipeline\nfrom snowflake.cortex import complete\nfrom trulens.core.otel.instrument import instrument\nfrom trulens.otel.semconv.trace import SpanAttributes\n\n\nclass RAG():\n    def __init__(self, llm_model, cortex_search_service_name):\n        self.llm_model = llm_model\n        self.cortex_search_service_name = cortex_search_service_name\n#Here we're using the @instrument decorator to trace various stages of our RAG applicaiton\n\n\n#RETRIEVEL FUNCTION\n    \n    @instrument (\n        span_type=SpanAttributes.SpanType.RETRIEVAL, \n        attributes={\n            SpanAttributes.RETRIEVAL.QUERY_TEXT: \"query\",\n            SpanAttributes.RETRIEVAL.RETRIEVED_CONTEXTS: \"return\",\n        })  \n    def retrieve_context(self, query: str):\n    \n        #First call cortex search service on knowledgebase!\n\n        cortex_search_service = (\n        root\n        .databases[DB_NAME]\n        .schemas[SCHEMA_NAME]\n        .cortex_search_services[self.cortex_search_service_name])\n\n        \n        css_response = cortex_search_service.search(\n            query=query,\n            columns=[\"SEARCH_COL\"],\n            limit=5)\n        \n        search_results = [(row[\"SEARCH_COL\"]) for row in resp.results] if resp.results else []\n\n        return search_results\n\n#PROMPT AUGMENTATION FUNCTION\n\n    @instrument()\n    def augment_prompt(self, query: str, contexts: list) -> str:\n     \n        prompt = f\"\"\"\n        You are an expert assistant extracting information from context provided on Federal Open Market Committee (FOMC)\n        Meeting notes.\n        Answer the question based on the context. Be sure to pay close attention to the dates in the user's query as well\n        as in the retrieved contexts.\n        Be concise and do not hallucinate.\n        If you don't have the information, just say so.\n        Context: {' '.join(contexts)}\n        Question: {query}\n        Answer:\n        \"\"\"\n        return prompt\n\n#COMPLETION FUNCTION\n\n    @instrument (span_type=SpanAttributes.SpanType.GENERATION)    \n    def generate_completion(self, query: str):\n        \n        df_response = complete(self.llm_model, query)\n        return df_response\n\n#ROOT FUNCTION\n    @instrument (\n        span_type=SpanAttributes.SpanType.RECORD_ROOT, \n        attributes={\n            SpanAttributes.RECORD_ROOT.INPUT: \"query\",\n            SpanAttributes.RECORD_ROOT.OUTPUT: \"return\",\n        })\n    def query_app(self, query: str) -> str:\n        st.write(query)\n        contexts = self.retrieve_context(query)\n        prompt = self.augment_prompt(query, contexts)\n        final_response = self.generate_completion(prompt)\n        st.write(final_response)\n        return final_response"
  },
  {
   "cell_type": "code",
   "id": "8467e565-8611-49e3-b259-b53c21a9f7ff",
   "metadata": {
    "language": "python",
    "name": "test_apps",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "import streamlit as st\n\ntest_query = \"How did interest rates change over the course of 2023-2025?\"\ntest_query = \"How did the economic outlook change over the course of 2023?\"\n\n\n# With web search agent disabled\nraw_chunk_rag = RAG(llm_model = 'openai-gpt-4.1', cortex_search_service_name='FOMC_RAW_TEXT_RETRIEVAL')\ntagged_chunk_rag = RAG(llm_model = 'openai-gpt-4.1', cortex_search_service_name='FOMC_TAGGED_CHUNK_RETRIEVAL')\n\n#Get and print results\nst.write(\"RAW_CHUNK\")\nllama_response = raw_chunk_rag.query_app(test_query)\n\nst.write(\"TAGGED_CHUNK\")\nmistral_response = tagged_chunk_rag.query_app(test_query)\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b58d853-417c-4d46-abfd-6c928613a45f",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "LLMObservabilitySetup",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# from trulens.core import TruSession\nfrom trulens.apps.app import TruApp\nfrom trulens.connectors.snowflake import SnowflakeConnector\n\ntru_snowflake_connector = SnowflakeConnector(snowpark_session=session)\n\napp_name = \"FOMC_RAG_CHUNKING_EVAL\"\nversion_num = 'v0'\n\ntru_raw_chunk_rag = TruApp(\n    raw_chunk_rag,\n    app_name=app_name,\n    app_version=f\"OAI_RAW_CHUNKS_{version_num}\",\n    connector=tru_snowflake_connector\n)\n\ntru_tagged_chunk_rag = TruApp(\n    tagged_chunk_rag,\n    app_name=app_name,\n    app_version=f\"OAI_TAGGED_CHUNKS_{version_num}\",\n    connector=tru_snowflake_connector\n)"
  },
  {
   "cell_type": "code",
   "id": "239dd11c-5b9a-40f9-a115-39692c06ed05",
   "metadata": {
    "language": "python",
    "name": "define_prompts",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "import pandas as pd\n\nprompts = [\n    \"What did the Fed decide about interest rates in June 2024?\",\n    \"What is the Fed's balance sheet policy?\",\n    \"Who is the Senior Vice President at the Federal Reserve Bank of Dallas?\",\n    \"What factors often contribute to future rate decreases?\",\n    \"Why did the FOMC keep rates unchanged despite strong economic growth in March 2023?\",\n    \"What is the largest increase in interest rates seen in 2023-2024?\",\n    \"What should Snowflake's target stock price be in 2025?\",\n    \"How often does the Fed meet?\",\n    \"Are interest rates just impactful for mortgages?\",\n    \"How has Asian economic growth impacted the US economy?\"\n    \n    \n]\n\nbatch_data = pd.DataFrame({'QUERY': prompts})\nbatch_data",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e86306d7-b0a9-4d12-af47-f881228d7d9d",
   "metadata": {
    "language": "python",
    "name": "define_run_configs",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "from trulens.core.run import Run\nfrom trulens.core.run import RunConfig\n\nrun_version = version_num\n\nraw_chunk_run_config = RunConfig(\n    run_name=f\"raw_chunk_run_{run_version}\",\n    description=\"questions about snowflake AI cababilities\",\n    dataset_name=\"SNOW_RAG_DF1\",\n    source_type=\"DATAFRAME\",\n    label=\"LOCAL\",\n    llm_judge_name = \"llama3.1-70b\",\n    dataset_spec={\n        \"RECORD_ROOT.INPUT\": \"QUERY\",\n    },\n)\n\n\n\ntagged_chunk_run_config = RunConfig(\n    run_name=f\"tagged_chunk_run_{run_version}\",\n    description=\"questions about snowflake AI cababilities\",\n    dataset_name=\"SNOW_RAG_DF1\",\n    source_type=\"DATAFRAME\",\n    label=\"LOCAL\",\n    dataset_spec={\n        \"RECORD_ROOT.INPUT\": \"QUERY\",\n    },\n    \n)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3e938ac2-5206-432e-bd8e-2597c1bc2998",
   "metadata": {
    "language": "python",
    "name": "add_runs",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "raw_chunk_run = tru_raw_chunk_rag.add_run(run_config=raw_chunk_run_config)\ntagged_chunk_run = tru_tagged_chunk_rag.add_run(run_config=tagged_chunk_run_config)\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "62e0bccb-5975-4481-b923-163b07798734",
   "metadata": {
    "language": "python",
    "name": "start_mistral_run",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "raw_chunk_run.start(input_df=batch_data)\nprint(\"Finished raw chunk run\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e66f72b7-75cf-4fb6-a55e-02e7284a2c02",
   "metadata": {
    "language": "python",
    "name": "start_llama_run",
    "codeCollapsed": false,
    "collapsed": true
   },
   "outputs": [],
   "source": "tagged_chunk_run.start(input_df=batch_data)\nprint(\"Finished tagged_chunk run\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "61207bef-6726-41e3-8b34-0857f15f7171",
   "metadata": {
    "language": "python",
    "name": "check_run_status_1",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "run_list = [raw_chunk_run, tagged_chunk_run]\n\nfor i in run_list:\n    print(f\"{i.run_name} Run Status: {i.get_status()}\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a76affd9-0862-4ff3-be08-25851e84ed11",
   "metadata": {
    "language": "python",
    "name": "compute_eval_metrics",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "#The following code kicks off LLM-as-a-Judge evals for several metrics\n\nfor i in run_list:\n    while i.get_status() == \"INVOCATION_IN_PROGRESS\":\n        time.sleep(3)\n    if i.get_status() == \"INVOCATION_COMPLETED\":\n        i.compute_metrics([\"coherence\",\n                           \"answer_relevance\",\n                           \"context_relevance\",\n                           \"groundedness\"])\n        print(f\"Kicked off Metrics Computation for Run {i.run_name}\")\n    if i.get_status() in [\"FAILED\", \"UNKNOWN\"]:\n        print(\"Not able to compute metrics! Run status:\", i.get_status())\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738df93c-8b06-43ef-9824-a9c1c209339a",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "generate_ai_obs_UI_link",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "import streamlit as st\n\norg_name = session.sql('SELECT CURRENT_ORGANIZATION_NAME()').collect()[0][0]\naccount_name = session.sql('SELECT CURRENT_ACCOUNT_NAME()').collect()[0][0]\ndb_name = session.sql('SELECT CURRENT_DATABASE()').collect()[0][0]\nschema_name = session.sql('SELECT CURRENT_SCHEMA()').collect()[0][0]\n\nst.write(f'https://app.snowflake.com/{org_name}/{account_name}/#/ai-evaluations/databases/{db_name}/schemas/{schema_name}/applications/{app_name.upper()}')"
  },
  {
   "cell_type": "markdown",
   "id": "ad0d40c5-249b-4989-8cc3-9ec329c9c90d",
   "metadata": {
    "name": "ARCHIVE_BELOW",
    "collapsed": false
   },
   "source": "# ARCHIVE BELOW"
  },
  {
   "cell_type": "code",
   "id": "d867346f-8d51-4460-ac0d-fc836aac0276",
   "metadata": {
    "language": "python",
    "name": "optional_cleanup"
   },
   "outputs": [],
   "source": "## Optional Cleanup\n# for i in run_list:\n#     i.delete()",
   "execution_count": null
  }
 ]
}