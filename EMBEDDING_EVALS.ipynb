{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "lastEditStatus": {
   "notebookId": "pr2jl6dpcoxvhwjia6dl",
   "authorId": "5095547476787",
   "authorName": "EBOTWICK",
   "authorEmail": "elliott.botwick@snowflake.com",
   "sessionId": "139117f7-8736-4a6b-9fd3-4e63391a3403",
   "lastEditTime": 1761671568847
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "id": "279ca787-64fa-4802-ac3c-490d6d111e5c",
   "metadata": {
    "language": "python",
    "name": "pip_installs",
    "collapsed": true,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "!pip install openai trulens-core trulens-feedback trulens-connectors-snowflake trulens-providers-cortex",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a1ee390b-c216-4c30-9cef-15e61b5a1acd",
   "metadata": {
    "language": "python",
    "name": "python_import"
   },
   "outputs": [],
   "source": "import pandas as pd\nimport numpy as np\n\nimport snowflake.core\nfrom snowflake.snowpark import Session\nfrom snowflake.core import Root\nimport snowflake.snowpark as snowpark\nfrom snowflake.snowpark.context import get_active_session\nfrom snowflake.cortex import complete\n\nfrom typing import List\nimport os\nimport sys\nimport json\nimport time\nimport requests\n\n#Set up snowflake session vars and env vars\nsession = get_active_session()\nroot = Root(session)\n\n#Enable OpenTelemetry Tracing\nos.environ[\"TRULENS_OTEL_TRACING\"] = \"1\"",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "86161c8a-fa0a-46b2-8368-a279c00be836",
   "metadata": {
    "language": "python",
    "name": "define_vars",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "DB_NAME = \"EMBEDDING_EVAL_DB\"\nSCHEMA_NAME = \"DATA\"\nWH_NAME = \"MEDIUM\"",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6181ef3b-7dbd-480d-8556-0b74b730f673",
   "metadata": {
    "language": "python",
    "name": "oai_api_key"
   },
   "outputs": [],
   "source": "oai_key = '<YOUR OAI KEY HERE>'\nprint('Stored API key in *oai_key* var')",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65daf34a-f360-4223-bff2-60f016ff6c3e",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "query_css_oai_embed",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "from openai import OpenAI\noai_client = OpenAI(api_key=oai_key)\n\n\n#Access cortex search retriever built in 1st notebook\ntest_query = \"Why might a discount code show as invalid during checkout?\"\n\n\ncss_oai_embed = (\n    root\n    .databases[DB_NAME]\n    .schemas[SCHEMA_NAME]\n    .cortex_search_services[\"SUPPORT_TICKET_SEARCH_OAI_EMBED\"]\n)\nresp = css_oai_embed.search(\n    multi_index_query={\n        \"OAI_EMB\": [\n            {\"vector\": oai_client.embeddings.create(input=test_query,\n                                                model=\"text-embedding-3-small\").data[0].embedding}\n        ],\n    },    columns=[\"CASE_DETAILS\"],\n    limit=3,\n)\n\nsearch_results = [(row[\"CASE_DETAILS\"]) for row in resp.results] if resp.results else []\n\nsearch_results"
  },
  {
   "cell_type": "code",
   "id": "7b6a0b34-68e5-4c65-899c-fc104cf2bb88",
   "metadata": {
    "language": "python",
    "name": "query_css_arctic_embed"
   },
   "outputs": [],
   "source": "#Access cortex search retriever built in 1st notebook\ntest_query = \"Why might a discount code show as invalid during checkout?\"\n\ncss_arctic_embed = (\n    root\n    .databases[DB_NAME]\n    .schemas[SCHEMA_NAME]\n    .cortex_search_services[\"SUPPORT_TICKET_SEARCH_ARCTIC_EMBED\"]\n)\nresp = css_arctic_embed.search(\n    query=test_query,\n    columns=[\"CASE_DETAILS\"],\n    limit=3,\n)\n\nsearch_results = [(row[\"CASE_DETAILS\"]) for row in resp.results] if resp.results else []\n\nsearch_results",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b51fe4-118c-437c-a348-462d2fb25f58",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "DefineRAGClass",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# Create the RAGWithObservability class to structure the RAG pipeline\nfrom snowflake.cortex import complete\nfrom trulens.core.otel.instrument import instrument\nfrom trulens.otel.semconv.trace import SpanAttributes\n\n\nclass RAG():\n    def __init__(self, llm_model, cortex_search_service_name):\n        self.llm_model = llm_model\n        self.cortex_search_service_name = cortex_search_service_name\n        \n#Here we're using the @instrument decorator to trace various stages of our RAG applicaiton\n\n#RETRIEVEL FUNCTION\n\n    @instrument()\n    def distill_query(self, query: str):\n        distilled_query = complete('llama4-maverick', f'''You are an expert query processor. Your sole function is to distill a complex \n                                user question into a minimal set of the most relevant, \n                                semantically rich keywords and key phrases suitable for a high-quality, \n                                targeted vector database search.\n                                Distill the following question: {query}\n                                ONLY return the key terms nothing else.\n                                Make the answer extermely minimal contained 3-5 key terms and absolutely no other text''')\n        return distilled_query \n        \n    @instrument (\n        span_type=SpanAttributes.SpanType.RETRIEVAL, \n        attributes={\n            SpanAttributes.RETRIEVAL.QUERY_TEXT: \"query\",\n            SpanAttributes.RETRIEVAL.RETRIEVED_CONTEXTS: \"return\",\n        })  \n    def retrieve_context(self, query: str):\n    \n        #First call cortex search service on knowledgebase!\n\n        cortex_search_service = (\n        root\n        .databases[DB_NAME]\n        .schemas[SCHEMA_NAME]\n        .cortex_search_services[self.cortex_search_service_name])\n\n        if self.cortex_search_service_name == \"SUPPORT_TICKET_SEARCH_ARCTIC_EMBED\":\n            resp = cortex_search_service.search(\n                query=query,\n                columns=[\"CASE_DETAILS\"],\n                limit=5)\n            \n            search_results = [(row[\"CASE_DETAILS\"]) for row in resp.results] if resp.results else []\n\n        elif self.cortex_search_service_name == \"SUPPORT_TICKET_SEARCH_OAI_EMBED\":\n            resp = cortex_search_service.search(\n            multi_index_query={\n                \"OAI_EMB\": [\n                    {\"vector\": oai_client.embeddings.create(input=query,\n                                                        model=\"text-embedding-3-small\").data[0].embedding}\n                ],\n            },    \n            columns=[\"CASE_DETAILS\"],\n            limit=5,\n            )\n            \n            search_results = [(row[\"CASE_DETAILS\"]) for row in resp.results] if resp.results else []\n\n        else:\n            print('Cant find cortex search service with that name!')\n            search_results = \"NONE FOUND\"\n            \n        return search_results\n\n#PROMPT AUGMENTATION FUNCTION\n\n    @instrument()\n    def augment_prompt(self, query: str, contexts: list) -> str:\n     \n        prompt = f\"\"\"\n        You are an expert assistant extracting information from context provided on Customer Support Case Details.\n        Answer the question based on the context. \n        Be concise and do not hallucinate.\n        If you don't have the information, just say so.\n        Context: {' '.join(contexts)}\n        Question: {query}\n        Answer:\n        \"\"\"\n        return prompt\n\n#COMPLETION FUNCTION\n\n    @instrument (span_type=SpanAttributes.SpanType.GENERATION)    \n    def generate_completion(self, query: str):\n        \n        df_response = complete(self.llm_model, query)\n        return df_response\n\n#ROOT FUNCTION\n    @instrument (\n        span_type=SpanAttributes.SpanType.RECORD_ROOT, \n        attributes={\n            SpanAttributes.RECORD_ROOT.INPUT: \"query\",\n            SpanAttributes.RECORD_ROOT.OUTPUT: \"return\",\n        })\n    def query_app(self, query: str) -> str:\n        st.write(query)\n        distilled_query = self.distill_query(query)\n        contexts = self.retrieve_context(distilled_query)\n        prompt = self.augment_prompt(query, contexts)\n        final_response = self.generate_completion(prompt)\n        st.write(final_response)\n        return final_response"
  },
  {
   "cell_type": "code",
   "id": "8467e565-8611-49e3-b259-b53c21a9f7ff",
   "metadata": {
    "language": "python",
    "name": "test_apps",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "import streamlit as st\n\ntest_query = \"What are some common themes we see around billing issues\"\n\n# With web search agent disabled\nrag_oai_embed = RAG(llm_model = 'claude-4-sonnet', cortex_search_service_name='SUPPORT_TICKET_SEARCH_OAI_EMBED')\nrag_arctic_embed = RAG(llm_model = 'claude-4-sonnet', cortex_search_service_name='SUPPORT_TICKET_SEARCH_ARCTIC_EMBED')\n\n#Get and print results\nst.write(\"OAI_EMBEDDING\")\nresponse_oai_embed = rag_oai_embed.query_app(test_query)\n\nst.write(\"ARCTIC_EMBEDDING\")\nresponse_arctic_embed = rag_arctic_embed.query_app(test_query)\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b58d853-417c-4d46-abfd-6c928613a45f",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "LLMObservabilitySetup",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# from trulens.core import TruSession\nfrom trulens.apps.app import TruApp\nfrom trulens.connectors.snowflake import SnowflakeConnector\n\ntru_snowflake_connector = SnowflakeConnector(snowpark_session=session)\n\napp_name = \"SUPPORT_TICKET_EMBEDDING_EVAL_DEMO\"\nversion_num = 'v0'\n\ntru_rag_oai_embed = TruApp(\n    rag_oai_embed,\n    app_name=app_name,\n    app_version=f\"OAI_EMBEDDINGS_{version_num}\",\n    comment = \"Rag with cortex search service using OAI embeddings\",\n    connector=tru_snowflake_connector   \n)\n\ntru_rag_arctic_embed = TruApp(\n    rag_arctic_embed,\n    app_name=app_name,\n    app_version=f\"ARCTIC_EMBEDDINGS_{version_num}\",\n    comment = \"Rag with cortex search service using Arctic embeddings\",\n    connector=tru_snowflake_connector\n)"
  },
  {
   "cell_type": "code",
   "id": "239dd11c-5b9a-40f9-a115-39692c06ed05",
   "metadata": {
    "language": "python",
    "name": "define_prompts",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "import pandas as pd\n\nprompts = [\n    \"What are some common themes with billing issues?\",\n    \"What issues do we see with promo codes?\",\n    \"What is the sentiment around issues with duplicate billing?\",\n    \"What issues are customers seeing around shipping?\",\n    \"How should someone resolve an issue related to payments not processing?\",\n    \"Are we refunding customers in a timely manner?\",\n    \"What is the top selling product we offer?\",\n    \"What are some of the promo codes we have offered? Which ones have had issues?\",\n    \"Who is the best player in the NBA?\",\n    \"Are smartphones shipping on time?\"\n]\n\nbatch_data = pd.DataFrame({'QUERY': prompts})\nbatch_data",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e86306d7-b0a9-4d12-af47-f881228d7d9d",
   "metadata": {
    "language": "python",
    "name": "define_run_configs",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "from trulens.core.run import Run\nfrom trulens.core.run import RunConfig\n\nrun_version = version_num\n\nrun_config_oai_embed = RunConfig(\n    run_name=f\"run_oai_embed_{run_version}\",\n    description=\"questions about snowflake AI cababilities\",\n    dataset_name=\"SNOW_RAG_DF1\",\n    source_type=\"DATAFRAME\",\n    label=\"LOCAL\",\n    llm_judge_name = \"llama3.1-70b\",\n    dataset_spec={\n        \"RECORD_ROOT.INPUT\": \"QUERY\",\n    },\n)\n\n\n\nrun_config_arctic_embed = RunConfig(\n    run_name=f\"run_arctic_embed_{run_version}\",\n    description=\"questions about snowflake AI cababilities\",\n    dataset_name=\"SNOW_RAG_DF1\",\n    source_type=\"DATAFRAME\",\n    label=\"LOCAL\",\n    dataset_spec={\n        \"RECORD_ROOT.INPUT\": \"QUERY\",\n    },\n    \n)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3e938ac2-5206-432e-bd8e-2597c1bc2998",
   "metadata": {
    "language": "python",
    "name": "add_runs",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "run_oai_embed = tru_rag_oai_embed.add_run(run_config=run_config_oai_embed)\nrun_arctic_embed = tru_rag_arctic_embed.add_run(run_config=run_config_arctic_embed)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "62e0bccb-5975-4481-b923-163b07798734",
   "metadata": {
    "language": "python",
    "name": "start_oai_embed_run",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "run_oai_embed.start(input_df=batch_data)\nprint(\"Finished oai embed run\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e66f72b7-75cf-4fb6-a55e-02e7284a2c02",
   "metadata": {
    "language": "python",
    "name": "start_arctic_embed_run",
    "codeCollapsed": false,
    "collapsed": true
   },
   "outputs": [],
   "source": "run_arctic_embed.start(input_df=batch_data)\nprint(\"Finished arctic embed run\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "61207bef-6726-41e3-8b34-0857f15f7171",
   "metadata": {
    "language": "python",
    "name": "check_run_status_1",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "run_list = [run_oai_embed, run_arctic_embed]\n\nfor i in run_list:\n    print(f\"{i.run_name} Run Status: {i.get_status()}\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a76affd9-0862-4ff3-be08-25851e84ed11",
   "metadata": {
    "language": "python",
    "name": "compute_eval_metrics",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "#The following code kicks off LLM-as-a-Judge evals for several metrics\n\nfor i in run_list:\n    while i.get_status() == \"INVOCATION_IN_PROGRESS\":\n        time.sleep(3)\n    if i.get_status() == \"INVOCATION_COMPLETED\":\n        i.compute_metrics([\"coherence\",\n                           \"answer_relevance\",\n                           \"context_relevance\",\n                           \"groundedness\"])\n        print(f\"Kicked off Metrics Computation for Run {i.run_name}\")\n    if i.get_status() in [\"FAILED\", \"UNKNOWN\"]:\n        print(\"Not able to compute metrics! Run status:\", i.get_status())\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738df93c-8b06-43ef-9824-a9c1c209339a",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "generate_ai_obs_UI_link",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "import streamlit as st\n\norg_name = session.sql('SELECT CURRENT_ORGANIZATION_NAME()').collect()[0][0]\naccount_name = session.sql('SELECT CURRENT_ACCOUNT_NAME()').collect()[0][0]\ndb_name = session.sql('SELECT CURRENT_DATABASE()').collect()[0][0]\nschema_name = session.sql('SELECT CURRENT_SCHEMA()').collect()[0][0]\n\nst.write(f'https://app.snowflake.com/{org_name}/{account_name}/#/ai-evaluations/databases/{db_name}/schemas/{schema_name}/applications/{app_name.upper()}')"
  },
  {
   "cell_type": "markdown",
   "id": "ad0d40c5-249b-4989-8cc3-9ec329c9c90d",
   "metadata": {
    "name": "ARCHIVE_BELOW",
    "collapsed": false
   },
   "source": "# ARCHIVE BELOW"
  },
  {
   "cell_type": "code",
   "id": "a17ae287-257d-484e-a0a0-09c932ad9c7c",
   "metadata": {
    "language": "sql",
    "name": "cell10"
   },
   "outputs": [],
   "source": "SHOW TABLES in SNOWFLAKE.LOCAL;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1ae7f4ea-b2ac-44e4-b442-ca1e8d48db00",
   "metadata": {
    "language": "sql",
    "name": "cell9"
   },
   "outputs": [],
   "source": "SELECT * FROM SNOWFLAKE.LOCAL.AI_OBSERVABILITY_EVENTS;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d867346f-8d51-4460-ac0d-fc836aac0276",
   "metadata": {
    "language": "python",
    "name": "optional_cleanup"
   },
   "outputs": [],
   "source": "## Optional Cleanup\n# for i in run_list:\n#     i.delete()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d5f99195-0294-4890-b5f8-1b8d8a2402d0",
   "metadata": {
    "language": "python",
    "name": "cell8"
   },
   "outputs": [],
   "source": "# query = 'what are the most common issues with billing'\n# print(complete('llama4-maverick', f'''Distill the following query into its key terms: {query}.\n#                                 Only return the key terms. Nothing else. \n#                                 Make the answer extermely minimal contained 3-5 key terms and absolutely no other text'''))\n\n\n# print(complete('llama4-maverick', f'''You are an expert query processor. Your sole function is to distill a complex \n#                                 user question into a minimal set of the most relevant, \n#                                 semantically rich keywords and key phrases suitable for a high-quality, \n#                                 targeted vector database search.\n#                                 Distill the following question: {query}\n#                                 ONLY return the key terms nothing else.\n#                                 Make the answer extermely minimal contained 3-5 key terms and absolutely no other text'''))",
   "execution_count": null
  }
 ]
}